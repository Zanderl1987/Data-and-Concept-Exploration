{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import urllib3\n",
    "from urllib3 import *\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from pandas import ExcelWriter\n",
    "import pandas_datareader.data as wb\n",
    "#import pandas_datareader as pdr\n",
    "#from pandas_datareader import *\n",
    "#from pandas_datareader import data, wb\n",
    "#import pandas.io.data as wb\n",
    "#from pandas.io.data import Options\n",
    "#from pandas_datareader import Options\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import spearmanr\n",
    "import sys\n",
    "import datetime\n",
    "from Quandl import Quandl\n",
    "import os\n",
    "import time\n",
    "import matplotlib.cbook as cbook\n",
    "import html5lib\n",
    "import csv\n",
    "import urllib2\n",
    "from urllib2 import *\n",
    "import statsmodels.formula.api as sm\n",
    "import seaborn as sns\n",
    "import math as mth\n",
    "from math import exp\n",
    "import pylab\n",
    "#import pymc3 as pm\n",
    "#from pymc3 import *\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import html2text\n",
    "import nltk\n",
    "from selenium import webdriver\n",
    "import string\n",
    "import pprint\n",
    "import sklearn\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import cross_validation\n",
    "from sklearn import grid_search\n",
    "from sklearn.cross_validation import cross_val_score, ShuffleSplit, cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sklearn.preprocessing, sklearn.pipeline\n",
    "\n",
    "import pandas_ml as pdml\n",
    "from sklearn_pandas import DataFrameMapper, cross_val_score\n",
    "\n",
    "sns.set_style(\"dark\")\n",
    "#sns.set_style(\"darkgrid\")\n",
    "#sns.set(style=\"darkgrid\", palette=\"Set2\")\n",
    "#sns.set(style=\"darkgrid\", context=\"paper\", font=\"monospace\")\n",
    "\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.core.panel.Panel'>\n",
       "Dimensions: 6 (items) x 1891 (major_axis) x 40 (minor_axis)\n",
       "Items axis: Open to Adj Close\n",
       "Major_axis axis: 2009-01-02 00:00:00 to 2016-07-07 00:00:00\n",
       "Minor_axis axis: AAP to ^VIX"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sd = pd.read_csv(\"C:\\Users\\zanderl\\Documents\\ShortFloatDataCSV.csv\",index_col=0, parse_dates=True)\n",
    "#sd = pd.read_excel(\"C:\\Users\\zanderl\\Documents\\Short Float Research 2_v2.xlsx\",sheetname='To CSV Export',index_col=0,parse_dates=True,na_values='NM')\n",
    "#sd = pd.read_excel(\"C:\\Users\\zanderl\\Documents\\FX_Data_1.xlsx\",sheetname='AUDUSD',index_col=0,parse_dates=True,na_values='NM')\n",
    "\n",
    "start = datetime.datetime(2009,1,1)\n",
    "end = datetime.datetime.today()\n",
    "\n",
    "\n",
    "ticker_list = [\n",
    "'BLK',\n",
    "'BBBY',\n",
    "'REGN',\n",
    "'CMG',\n",
    "'AMGN',\n",
    "'ALXN',\n",
    "'IBB',\n",
    "'BIIB',\n",
    "'BIDU',\n",
    "'FB',\n",
    "'GS',\n",
    "'ULTA',\n",
    "'NFLX',\n",
    "'TSLA',\n",
    "'WYNN',\n",
    "'GOOGL',\n",
    "'AMZN',\n",
    "'PCLN',\n",
    "'AGN',\n",
    "'AAP',\n",
    "'ELLI',\n",
    "'^GSPC',\n",
    "'AAPL',\n",
    "'CVX',\n",
    "'XOM',\n",
    "'CME',\n",
    "'C',\n",
    "'COST',\n",
    "'DAL',\n",
    "'GWPH',\n",
    "'^DJI',\n",
    "'^VIX',\n",
    "'JPM',\n",
    "'V',\n",
    "'SCTY',\n",
    "'FSLR',\n",
    "'FDX',\n",
    "'FAST',\n",
    "'HD',\n",
    "'ILMN']\n",
    "\n",
    "\n",
    "#ticker_list = ['GOOGL','TSLA','PCLN','AMZN']\n",
    "\n",
    "def stock_data():\n",
    "    for ticker in ticker_list:\n",
    "        stks = wb.DataReader(ticker_list, 'yahoo', start, end)\n",
    "    return stks\n",
    "\n",
    "#df = stock_data()\n",
    "\n",
    "#df = df.fillna(method='pad',axis='minor_axis',inplace=True)\n",
    "#df = df.fillna(method='bfill',axis='minor_axis',inplace=True)\n",
    "\n",
    "#sd = df\n",
    "stock_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.panel.Panel'>\n",
      "Dimensions: 6 (items) x 1891 (major_axis) x 40 (minor_axis)\n",
      "Items axis: Open to Adj Close\n",
      "Major_axis axis: 2009-01-02 00:00:00 to 2016-07-07 00:00:00\n",
      "Minor_axis axis: AAP to ^VIX\n"
     ]
    }
   ],
   "source": [
    "df = stock_data()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AGN</th>\n",
       "      <th>ALXN</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BBBY</th>\n",
       "      <th>BIDU</th>\n",
       "      <th>BIIB</th>\n",
       "      <th>BLK</th>\n",
       "      <th>...</th>\n",
       "      <th>^VIX</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Day of year</th>\n",
       "      <th>Days_in_month</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week of year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>y_future</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>83.828116</td>\n",
       "      <td>58.618327</td>\n",
       "      <td>104.389999</td>\n",
       "      <td>96.669998</td>\n",
       "      <td>97.913159</td>\n",
       "      <td>248.229996</td>\n",
       "      <td>68.609082</td>\n",
       "      <td>84.860001</td>\n",
       "      <td>214.330002</td>\n",
       "      <td>240.794253</td>\n",
       "      <td>...</td>\n",
       "      <td>14.49</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1617.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-02</th>\n",
       "      <td>84.076599</td>\n",
       "      <td>59.449650</td>\n",
       "      <td>106.489998</td>\n",
       "      <td>96.199997</td>\n",
       "      <td>98.896594</td>\n",
       "      <td>252.550003</td>\n",
       "      <td>69.516429</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>217.300003</td>\n",
       "      <td>242.095398</td>\n",
       "      <td>...</td>\n",
       "      <td>13.59</td>\n",
       "      <td>3</td>\n",
       "      <td>122</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1625.959961</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-03</th>\n",
       "      <td>84.046782</td>\n",
       "      <td>60.044790</td>\n",
       "      <td>106.459999</td>\n",
       "      <td>98.169998</td>\n",
       "      <td>99.730183</td>\n",
       "      <td>258.049988</td>\n",
       "      <td>68.369785</td>\n",
       "      <td>84.510002</td>\n",
       "      <td>218.850006</td>\n",
       "      <td>250.391321</td>\n",
       "      <td>...</td>\n",
       "      <td>12.85</td>\n",
       "      <td>4</td>\n",
       "      <td>123</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1632.689941</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-06</th>\n",
       "      <td>84.394664</td>\n",
       "      <td>61.476583</td>\n",
       "      <td>107.199997</td>\n",
       "      <td>97.070000</td>\n",
       "      <td>98.184776</td>\n",
       "      <td>255.720001</td>\n",
       "      <td>69.446634</td>\n",
       "      <td>87.650002</td>\n",
       "      <td>215.729996</td>\n",
       "      <td>253.168944</td>\n",
       "      <td>...</td>\n",
       "      <td>12.66</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1626.670044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-07</th>\n",
       "      <td>85.060596</td>\n",
       "      <td>61.203037</td>\n",
       "      <td>107.220001</td>\n",
       "      <td>96.349998</td>\n",
       "      <td>97.838228</td>\n",
       "      <td>257.730011</td>\n",
       "      <td>69.865406</td>\n",
       "      <td>89.300003</td>\n",
       "      <td>212.550003</td>\n",
       "      <td>254.276282</td>\n",
       "      <td>...</td>\n",
       "      <td>12.83</td>\n",
       "      <td>1</td>\n",
       "      <td>127</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1633.699951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAP       AAPL         AGN       ALXN       AMGN  \\\n",
       "Date                                                                 \n",
       "2013-05-01  83.828116  58.618327  104.389999  96.669998  97.913159   \n",
       "2013-05-02  84.076599  59.449650  106.489998  96.199997  98.896594   \n",
       "2013-05-03  84.046782  60.044790  106.459999  98.169998  99.730183   \n",
       "2013-05-06  84.394664  61.476583  107.199997  97.070000  98.184776   \n",
       "2013-05-07  85.060596  61.203037  107.220001  96.349998  97.838228   \n",
       "\n",
       "                  AMZN       BBBY       BIDU        BIIB         BLK   ...    \\\n",
       "Date                                                                   ...     \n",
       "2013-05-01  248.229996  68.609082  84.860001  214.330002  240.794253   ...     \n",
       "2013-05-02  252.550003  69.516429  85.000000  217.300003  242.095398   ...     \n",
       "2013-05-03  258.049988  68.369785  84.510002  218.850006  250.391321   ...     \n",
       "2013-05-06  255.720001  69.446634  87.650002  215.729996  253.168944   ...     \n",
       "2013-05-07  257.730011  69.865406  89.300003  212.550003  254.276282   ...     \n",
       "\n",
       "             ^VIX  Weekday  Day of year  Days_in_month  Month  Week of year  \\\n",
       "Date                                                                          \n",
       "2013-05-01  14.49        2          121             31      5            18   \n",
       "2013-05-02  13.59        3          122             31      5            18   \n",
       "2013-05-03  12.85        4          123             31      5            18   \n",
       "2013-05-06  12.66        0          126             31      5            19   \n",
       "2013-05-07  12.83        1          127             31      5            19   \n",
       "\n",
       "            Quarter  Year     y_future  labels  \n",
       "Date                                            \n",
       "2013-05-01        2  2013  1617.500000       1  \n",
       "2013-05-02        2  2013  1625.959961       1  \n",
       "2013-05-03        2  2013  1632.689941       1  \n",
       "2013-05-06        2  2013  1626.670044       1  \n",
       "2013-05-07        2  2013  1633.699951       1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd = df['Adj Close']\n",
    "\n",
    "sd['Weekday'] = sd.index.dayofweek\n",
    "sd['Day of year'] = sd.index.dayofyear\n",
    "sd['Days_in_month'] = sd.index.days_in_month\n",
    "sd['Month'] = sd.index.month\n",
    "sd['Week of year'] = sd.index.weekofyear\n",
    "sd['Quarter'] = sd.index.quarter\n",
    "sd['Year'] = sd.index.year\n",
    "\n",
    "'''\n",
    "n=4.0\n",
    "e_y = (1.0/n)\n",
    "\n",
    "d_i = 10.0\n",
    "a_i = 5.0\n",
    "j_i = 3.0\n",
    "\n",
    "d_n = 2.0\n",
    "a_n = 2.0\n",
    "j_n = 2.0\n",
    "\n",
    "sd['prod_gm'] = (sd['Open'] * sd['High'] * sd['Low'] * sd['Close Price Adjusted'])\n",
    "sd['GeoMean'] = sd['prod_gm'].apply(lambda x: mth.pow(x,e_y))\n",
    "\n",
    "sd['LnR_GeoMean_Delta'] = ((np.log(sd['GeoMean']) - np.log(sd['GeoMean']).shift(d_i)) / d_n)\n",
    "sd['Exp_Delta'] = sd['LnR_GeoMean_Delta'].apply(lambda x: np.exp(x))\n",
    "\n",
    "sd['LnR_GeoMean_Accel'] = ((np.log(sd['Exp_Delta']) - np.log(sd['Exp_Delta']).shift(a_i)) / a_n)\n",
    "sd['Exp_Accel'] = sd['LnR_GeoMean_Accel'].apply(lambda x: np.exp(x))\n",
    "\n",
    "sd['LnR_GeoMean_Jerk'] = ((np.log(sd['Exp_Accel']) - np.log(sd['Exp_Accel']).shift(j_i)) / j_n)\n",
    "sd['Exp_Jerk'] = sd['LnR_GeoMean_Jerk'].apply(lambda x: np.exp(x))\n",
    "\n",
    "sd['OneLine'] = 1.00\n",
    "'''\n",
    "\n",
    "sd.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAP              0\n",
       "AAPL             0\n",
       "AGN              0\n",
       "ALXN             0\n",
       "AMGN             0\n",
       "AMZN             0\n",
       "BBBY             0\n",
       "BIDU             0\n",
       "BIIB             0\n",
       "BLK              0\n",
       "C                0\n",
       "CME              0\n",
       "CMG              0\n",
       "COST             0\n",
       "CVX              0\n",
       "DAL              0\n",
       "ELLI             0\n",
       "FAST             0\n",
       "FB               0\n",
       "FDX              0\n",
       "FSLR             0\n",
       "GOOGL            0\n",
       "GS               0\n",
       "GWPH             0\n",
       "HD               0\n",
       "IBB              0\n",
       "ILMN             0\n",
       "JPM              0\n",
       "NFLX             0\n",
       "PCLN             0\n",
       "REGN             0\n",
       "SCTY             0\n",
       "TSLA             0\n",
       "ULTA             0\n",
       "V                0\n",
       "WYNN             0\n",
       "XOM              0\n",
       "^DJI             0\n",
       "^GSPC            0\n",
       "^VIX             0\n",
       "Weekday          0\n",
       "Day of year      0\n",
       "Days_in_month    0\n",
       "Month            0\n",
       "Week of year     0\n",
       "Quarter          0\n",
       "Year             0\n",
       "y_future         0\n",
       "labels           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sd.drop(['Bid Price','Offer Price','Quarter','Year','Days_in_month','Close Price Adjusted'],axis=1,inplace=True)\n",
    "#sd.drop(['Month','Weekday','Last Sale Price','Market Cap',\n",
    "#         'Year','Quarter','Days_in_month','Week of year','Short Float (%)',\n",
    "#        'Bid Price','Offer Price','Low','High','Open'],axis=1,inplace=True)\n",
    "pd.isnull(sd).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.fillna(method='pad',axis=0,inplace=True)\n",
    "#sd.replace({'NM':'NaN'})\n",
    "sd.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAP              0\n",
       "AAPL             0\n",
       "AGN              0\n",
       "ALXN             0\n",
       "AMGN             0\n",
       "AMZN             0\n",
       "BBBY             0\n",
       "BIDU             0\n",
       "BIIB             0\n",
       "BLK              0\n",
       "C                0\n",
       "CME              0\n",
       "CMG              0\n",
       "COST             0\n",
       "CVX              0\n",
       "DAL              0\n",
       "ELLI             0\n",
       "FAST             0\n",
       "FB               0\n",
       "FDX              0\n",
       "FSLR             0\n",
       "GOOGL            0\n",
       "GS               0\n",
       "GWPH             0\n",
       "HD               0\n",
       "IBB              0\n",
       "ILMN             0\n",
       "JPM              0\n",
       "NFLX             0\n",
       "PCLN             0\n",
       "REGN             0\n",
       "SCTY             0\n",
       "TSLA             0\n",
       "ULTA             0\n",
       "V                0\n",
       "WYNN             0\n",
       "XOM              0\n",
       "^DJI             0\n",
       "^GSPC            0\n",
       "^VIX             0\n",
       "Weekday          0\n",
       "Day of year      0\n",
       "Days_in_month    0\n",
       "Month            0\n",
       "Week of year     0\n",
       "Quarter          0\n",
       "Year             0\n",
       "y_future         0\n",
       "labels           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.isnull(sd).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sd['Short Float (%)'].plot(figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dvar(d_curr,d_fut):\n",
    "    if d_fut > d_curr:\n",
    "        return 1\n",
    "    if d_fut < d_curr:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AGN</th>\n",
       "      <th>ALXN</th>\n",
       "      <th>AMGN</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>BBBY</th>\n",
       "      <th>BIDU</th>\n",
       "      <th>BIIB</th>\n",
       "      <th>BLK</th>\n",
       "      <th>...</th>\n",
       "      <th>^VIX</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Day of year</th>\n",
       "      <th>Days_in_month</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week of year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>y_future</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-05-01</th>\n",
       "      <td>83.828116</td>\n",
       "      <td>58.618327</td>\n",
       "      <td>104.389999</td>\n",
       "      <td>96.669998</td>\n",
       "      <td>97.913159</td>\n",
       "      <td>248.229996</td>\n",
       "      <td>68.609082</td>\n",
       "      <td>84.860001</td>\n",
       "      <td>214.330002</td>\n",
       "      <td>240.794253</td>\n",
       "      <td>...</td>\n",
       "      <td>14.49</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2013</td>\n",
       "      <td>1617.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAP       AAPL         AGN       ALXN       AMGN  \\\n",
       "Date                                                                 \n",
       "2013-05-01  83.828116  58.618327  104.389999  96.669998  97.913159   \n",
       "\n",
       "                  AMZN       BBBY       BIDU        BIIB         BLK   ...    \\\n",
       "Date                                                                   ...     \n",
       "2013-05-01  248.229996  68.609082  84.860001  214.330002  240.794253   ...     \n",
       "\n",
       "             ^VIX  Weekday  Day of year  Days_in_month  Month  Week of year  \\\n",
       "Date                                                                          \n",
       "2013-05-01  14.49        2          121             31      5            18   \n",
       "\n",
       "            Quarter  Year  y_future  labels  \n",
       "Date                                         \n",
       "2013-05-01        2  2013    1617.5       1  \n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1 = df1.apply(lambda x: np.log(x))\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAP',\n",
       " 'AAPL',\n",
       " 'AGN',\n",
       " 'ALXN',\n",
       " 'AMGN',\n",
       " 'AMZN',\n",
       " 'BBBY',\n",
       " 'BIDU',\n",
       " 'BIIB',\n",
       " 'BLK',\n",
       " 'C',\n",
       " 'CME',\n",
       " 'CMG',\n",
       " 'COST',\n",
       " 'CVX',\n",
       " 'DAL',\n",
       " 'ELLI',\n",
       " 'FAST',\n",
       " 'FB',\n",
       " 'FDX',\n",
       " 'FSLR',\n",
       " 'GOOGL',\n",
       " 'GS',\n",
       " 'GWPH',\n",
       " 'HD',\n",
       " 'IBB',\n",
       " 'ILMN',\n",
       " 'JPM',\n",
       " 'NFLX',\n",
       " 'PCLN',\n",
       " 'REGN',\n",
       " 'SCTY',\n",
       " 'TSLA',\n",
       " 'ULTA',\n",
       " 'V',\n",
       " 'WYNN',\n",
       " 'XOM',\n",
       " '^DJI',\n",
       " '^GSPC',\n",
       " '^VIX',\n",
       " 'Weekday',\n",
       " 'Day of year',\n",
       " 'Days_in_month',\n",
       " 'Month',\n",
       " 'Week of year',\n",
       " 'Quarter',\n",
       " 'Year',\n",
       " 'y_future',\n",
       " 'labels']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df1.columns\n",
    "feature_names = list(df1.columns.values)\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 49)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 49)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "st='^GSPC'\n",
    "df1['y_future'] = df1[st].shift(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['labels'] = list(map(dvar,df1[st],df1['y_future']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df1, index=df1.index)\n",
    "y = pd.DataFrame(df1, index=df1.index)\n",
    "\n",
    "X = X.drop(['y_future', 'labels'],axis=1)\n",
    "y = df1['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.isnull(df1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAP              0\n",
       "AAPL             0\n",
       "AGN              0\n",
       "ALXN             0\n",
       "AMGN             0\n",
       "AMZN             0\n",
       "BBBY             0\n",
       "BIDU             0\n",
       "BIIB             0\n",
       "BLK              0\n",
       "C                0\n",
       "CME              0\n",
       "CMG              0\n",
       "COST             0\n",
       "CVX              0\n",
       "DAL              0\n",
       "ELLI             0\n",
       "FAST             0\n",
       "FB               0\n",
       "FDX              0\n",
       "FSLR             0\n",
       "GOOGL            0\n",
       "GS               0\n",
       "GWPH             0\n",
       "HD               0\n",
       "IBB              0\n",
       "ILMN             0\n",
       "JPM              0\n",
       "NFLX             0\n",
       "PCLN             0\n",
       "REGN             0\n",
       "SCTY             0\n",
       "TSLA             0\n",
       "ULTA             0\n",
       "V                0\n",
       "WYNN             0\n",
       "XOM              0\n",
       "^DJI             0\n",
       "^GSPC            0\n",
       "^VIX             0\n",
       "Weekday          0\n",
       "Day of year      0\n",
       "Days_in_month    0\n",
       "Month            0\n",
       "Week of year     0\n",
       "Quarter          0\n",
       "Year             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.dropna(inplace=True)\n",
    "#X.replace({'NM':'NaN'})\n",
    "pd.isnull(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples=800\n",
      "n_features=47\n"
     ]
    }
   ],
   "source": [
    "n_samples, n_features = X.shape\n",
    "print(\"n_samples=%d\" % n_samples)\n",
    "print(\"n_features=%d\" % n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y, test_size=0.50)\n",
    "cv = ShuffleSplit(n_samples,n_iter=10,test_size=.50,random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [(\"LR\", LogisticRegression()),\n",
    "         (\"LDA\", LDA()),\n",
    "         (\"QDA\", QDA()),\n",
    "         (\"LSVC\", LinearSVC()),\n",
    "         (\"RSVM\", SVC(C=1000000.0, cache_size=200, kernel='rbf',gamma=0.0001,\n",
    "                      probability=True,random_state=None,shrinking=True,\n",
    "                      tol=0.001,verbose=False)\n",
    "          ),\n",
    "         (\"RF\", RandomForestClassifier(n_estimators=100,criterion='gini',max_depth=None,min_samples_split=2,\n",
    "                                       min_samples_leaf=1,max_features='auto',bootstrap=False,oob_score=False,\n",
    "                                       n_jobs=-1,random_state=None,verbose=0)\n",
    "         ),\n",
    "         (\"KNN\", KNeighborsClassifier()LD\n",
    "          ),\n",
    "          (\"ETC\", ExtraTreesClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "                                      min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                      max_features='auto', max_leaf_nodes=None, bootstrap=False, \n",
    "                                      oob_score=False, n_jobs=-1, random_state=None, verbose=0, \n",
    "                                      warm_start=False, class_weight=None))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll iterate through the models with a loop that trains them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:\n",
      "0.675\n",
      "[[ 78   0  44]\n",
      " [  0   0   0]\n",
      " [ 83   3 192]]\n",
      "\n",
      "LDA:\n",
      "0.665\n",
      "[[ 85   1  55]\n",
      " [  0   0   0]\n",
      " [ 76   2 181]]\n",
      "\n",
      "QDA:\n",
      "0.675\n",
      "[[ 76   0  42]\n",
      " [  0   0   0]\n",
      " [ 85   3 194]]\n",
      "\n",
      "LSVC:\n",
      "0.680\n",
      "[[ 86   0  50]\n",
      " [  0   0   0]\n",
      " [ 75   3 186]]\n",
      "\n",
      "RSVM:\n",
      "0.715\n",
      "[[103   0  53]\n",
      " [  0   0   0]\n",
      " [ 58   3 183]]\n",
      "\n",
      "RF:\n",
      "0.748\n",
      "[[109   2  46]\n",
      " [  0   0   0]\n",
      " [ 52   1 190]]\n",
      "\n",
      "KNN:\n",
      "0.637\n",
      "[[ 86   0  67]\n",
      " [  0   0   0]\n",
      " [ 75   3 169]]\n",
      "\n",
      "ETC:\n",
      "0.743\n",
      "[[102   0  41]\n",
      " [  0   0   0]\n",
      " [ 59   3 195]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    #Train the models on the training data\n",
    "    m[1].fit(X_train, y_train)\n",
    "    \n",
    "    #Make an array of predictions on the testing data in the test set\n",
    "    pred = m[1].predict(X_test)\n",
    "    \n",
    "    print(\"%s:\\n%0.3f\" % (m[0], m[1].score(X_test, y_test)))\n",
    "    print(\"%s\\n\" % confusion_matrix(pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF2 = RandomForestClassifier(n_estimators=100,criterion='gini',max_depth=None,min_samples_split=2,\n",
    "                                       min_samples_leaf=1,max_features='auto',bootstrap=False,oob_score=False,\n",
    "                                       n_jobs=-1,random_state=None,verbose=0)\n",
    "\n",
    "ETC2 = ExtraTreesClassifier(n_estimators=100, criterion='gini', max_depth=None, \n",
    "                                      min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                      max_features='auto', max_leaf_nodes=None, bootstrap=False, \n",
    "                                      oob_score=False, n_jobs=-1, random_state=None, verbose=0, \n",
    "                                      warm_start=False, class_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF2.fit(X_train, y_train)\n",
    "ETC2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print \"Features sorted by their score:\"\n",
    "#print sorted(zip(map(lambda x: round(x, 4), RF2.feature_importances_), feature_names),\n",
    "#             reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0399, 'FAST'),\n",
       " (0.0374, '^VIX'),\n",
       " (0.0363, 'JPM'),\n",
       " (0.0328, 'WYNN'),\n",
       " (0.0307, 'C'),\n",
       " (0.0282, 'GOOGL'),\n",
       " (0.0281, 'SCTY'),\n",
       " (0.0275, 'ULTA'),\n",
       " (0.0268, 'GS'),\n",
       " (0.0265, 'PCLN'),\n",
       " (0.0263, 'CMG'),\n",
       " (0.0258, '^DJI'),\n",
       " (0.0252, 'AGN'),\n",
       " (0.0251, 'BLK'),\n",
       " (0.0236, 'DAL'),\n",
       " (0.0231, 'NFLX'),\n",
       " (0.0231, 'FDX'),\n",
       " (0.0229, '^GSPC'),\n",
       " (0.0229, 'BIIB'),\n",
       " (0.0225, 'V'),\n",
       " (0.0222, 'AAPL'),\n",
       " (0.0221, 'Day of year'),\n",
       " (0.0219, 'XOM'),\n",
       " (0.0218, 'REGN'),\n",
       " (0.0216, 'TSLA'),\n",
       " (0.0211, 'CVX'),\n",
       " (0.0208, 'FSLR'),\n",
       " (0.0208, 'CME'),\n",
       " (0.0203, 'Week of year'),\n",
       " (0.0203, 'AAP'),\n",
       " (0.0194, 'AMGN'),\n",
       " (0.0193, 'ELLI'),\n",
       " (0.0192, 'ILMN'),\n",
       " (0.019, 'BIDU'),\n",
       " (0.0187, 'FB'),\n",
       " (0.0186, 'HD'),\n",
       " (0.0184, 'BBBY'),\n",
       " (0.0182, 'GWPH'),\n",
       " (0.0178, 'COST'),\n",
       " (0.0172, 'ALXN'),\n",
       " (0.0166, 'AMZN'),\n",
       " (0.0136, 'IBB'),\n",
       " (0.0056, 'Weekday'),\n",
       " (0.0054, 'Month'),\n",
       " (0.0033, 'Days_in_month'),\n",
       " (0.0016, 'Quarter'),\n",
       " (0.0007, 'Year')]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance = sorted(zip(map(lambda x: round(x, 4), RF2.feature_importances_), feature_names),\n",
    "             reverse=True)\n",
    "print \"Features sorted by their score:\"\n",
    "feat_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.0586, 'FAST'),\n",
       " (0.041, 'GS'),\n",
       " (0.0338, '^GSPC'),\n",
       " (0.0317, 'GOOGL'),\n",
       " (0.0312, 'AMGN'),\n",
       " (0.0311, 'C'),\n",
       " (0.0279, 'BLK'),\n",
       " (0.0258, 'AGN'),\n",
       " (0.0253, 'CMG'),\n",
       " (0.0249, '^DJI'),\n",
       " (0.0244, 'Day of year'),\n",
       " (0.0243, '^VIX'),\n",
       " (0.024, 'ULTA'),\n",
       " (0.0235, 'TSLA'),\n",
       " (0.0234, 'FSLR'),\n",
       " (0.0231, 'CVX'),\n",
       " (0.0228, 'REGN'),\n",
       " (0.0226, 'ELLI'),\n",
       " (0.0218, 'XOM'),\n",
       " (0.021, 'AAP'),\n",
       " (0.0209, 'Week of year'),\n",
       " (0.0205, 'BBBY'),\n",
       " (0.0204, 'AAPL'),\n",
       " (0.0199, 'GWPH'),\n",
       " (0.0198, 'AMZN'),\n",
       " (0.0197, 'SCTY'),\n",
       " (0.0197, 'HD'),\n",
       " (0.0196, 'V'),\n",
       " (0.0196, 'PCLN'),\n",
       " (0.0196, 'FDX'),\n",
       " (0.019, 'ILMN'),\n",
       " (0.019, 'COST'),\n",
       " (0.019, 'ALXN'),\n",
       " (0.0181, 'IBB'),\n",
       " (0.018, 'JPM'),\n",
       " (0.018, 'BIIB'),\n",
       " (0.0178, 'CME'),\n",
       " (0.0174, 'NFLX'),\n",
       " (0.0174, 'BIDU'),\n",
       " (0.0173, 'WYNN'),\n",
       " (0.0162, 'DAL'),\n",
       " (0.0154, 'FB'),\n",
       " (0.0106, 'Days_in_month'),\n",
       " (0.0061, 'Weekday'),\n",
       " (0.006, 'Month'),\n",
       " (0.0019, 'Quarter'),\n",
       " (0.0004, 'Year')]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance_ETC2 = sorted(zip(map(lambda x: round(x, 4), ETC2.feature_importances_), feature_names),\n",
    "             reverse=True)\n",
    "print \"Features sorted by their score:\"\n",
    "feat_importance_ETC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor cv_index, (train, test) in enumerate(cv):\\n    print(\"# Cross Validation Iteration #%d\" % cv_index)\\n    print(\"train indices: {0}...\".format(train[:10]))\\n    print(\"test indices: {0}...\".format(test[:10]))\\n    \\n    RF2 = RandomForestClassifier(n_estimators=50,criterion=\\'gini\\',max_depth=None,min_samples_split=2,\\n                                       min_samples_leaf=1,max_features=\\'auto\\',bootstrap=False,oob_score=False,\\n                                       n_jobs=-1,random_state=None,verbose=0).fit(X[train],y[train])\\n    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(RF2.score(X[train], y[train]), \\n          RF2.score(X[test], y[test])))\\n\\ntest_scores_2 = cross_val_score(RF2, X, y, cv=cv, n_jobs=-1)\\n'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for cv_index, (train, test) in enumerate(cv):\n",
    "    print(\"# Cross Validation Iteration #%d\" % cv_index)\n",
    "    print(\"train indices: {0}...\".format(train[:10]))\n",
    "    print(\"test indices: {0}...\".format(test[:10]))\n",
    "    \n",
    "    RF2 = RandomForestClassifier(n_estimators=50,criterion='gini',max_depth=None,min_samples_split=2,\n",
    "                                       min_samples_leaf=1,max_features='auto',bootstrap=False,oob_score=False,\n",
    "                                       n_jobs=-1,random_state=None,verbose=0).fit(X[train],y[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(RF2.score(X[train], y[train]), \n",
    "          RF2.score(X[test], y[test])))\n",
    "\n",
    "test_scores_2 = cross_val_score(RF2, X, y, cv=cv, n_jobs=-1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom scipy.stats import sem\\n\\ndef mean_score(scores):\\n    \"\"\"Print the empirical mean score and standard error of the mean.\"\"\"\\n    return (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))\\n\\nprint (test_scores_2)\\nprint (mean_score(test_scores_2))\\n'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from scipy.stats import sem\n",
    "\n",
    "def mean_score(scores):\n",
    "    \"\"\"Print the empirical mean score and standard error of the mean.\"\"\"\n",
    "    return (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))\n",
    "\n",
    "print (test_scores_2)\n",
    "print (mean_score(test_scores_2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor cv_index, (train, test) in enumerate(cv):\\n    print(\"# Cross Validation Iteration #%d\" % cv_index)\\n    print(\"train indices: {0}...\".format(train[:10]))\\n    print(\"test indices: {0}...\".format(test[:10]))\\n    \\n    ETC2 = RandomForestClassifier(n_estimators=50,criterion=\\'gini\\',max_depth=None,min_samples_split=2,\\n                                       min_samples_leaf=1,max_features=\\'auto\\',bootstrap=False,oob_score=False,\\n                                       n_jobs=-1,random_state=None,verbose=0).fit(X[train],y[train])\\n    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(ETC2.score(X[train], y[train]), \\n          ETC2.score(X[test], y[test])))\\n\\ntest_scores_3 = cross_val_score(ETC2, X, y, cv=cv, n_jobs=-1)\\n'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for cv_index, (train, test) in enumerate(cv):\n",
    "    print(\"# Cross Validation Iteration #%d\" % cv_index)\n",
    "    print(\"train indices: {0}...\".format(train[:10]))\n",
    "    print(\"test indices: {0}...\".format(test[:10]))\n",
    "    \n",
    "    ETC2 = RandomForestClassifier(n_estimators=50,criterion='gini',max_depth=None,min_samples_split=2,\n",
    "                                       min_samples_leaf=1,max_features='auto',bootstrap=False,oob_score=False,\n",
    "                                       n_jobs=-1,random_state=None,verbose=0).fit(X[train],y[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(ETC2.score(X[train], y[train]), \n",
    "          ETC2.score(X[test], y[test])))\n",
    "\n",
    "test_scores_3 = cross_val_score(ETC2, X, y, cv=cv, n_jobs=-1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom scipy.stats import sem\\n\\ndef mean_score(scores):\\n    \"\"\"Print the empirical mean score and standard error of the mean.\"\"\"\\n    return (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))\\n\\nprint (test_scores_3)\\nprint (mean_score(test_scores_3))\\n'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from scipy.stats import sem\n",
    "\n",
    "def mean_score(scores):\n",
    "    \"\"\"Print the empirical mean score and standard error of the mean.\"\"\"\n",
    "    return (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))\n",
    "\n",
    "print (test_scores_3)\n",
    "print (mean_score(test_scores_3))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_scores_3 = cross_val_score(knn, X, y, cv=cv, n_jobs=1)\n",
    "\n",
    "for cv_index, (train, test) in enumerate(cv):\n",
    "    print(\"# Cross Validation Iteration #%d\" % cv_index)\n",
    "    print(\"train indices: {0}...\".format(train[:10]))\n",
    "    print(\"test indices: {0}...\".format(test[:10]))\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=5,algorithm='auto').fit(X[train],y[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(knn.score(X[train], y[train]), \n",
    "          knn.score(X[test], y[test])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def mean_score(scores):\n",
    "    \"\"\"Print the empirical mean score and standard error of the mean.\"\"\"\n",
    "    return (\"Mean score: {0:.3f} (+/-{1:.3f})\").format(np.mean(scores), sem(scores))\n",
    "\n",
    "print (test_scores_3)\n",
    "print (mean_score(test_scores_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_values_RF2 = cross_val_predict(RF2,X_test,y_test,cv=10,n_jobs=-1,\n",
    "#                                        verbose=0,fit_params=None,pre_dispatch='2*n_jobs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_values_RF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor cv_index, (train, test) in enumerate(cv):\\n    print(\"# Cross Validation Iteration #%d\" % cv_index)\\n    print(\"train indices: {0}...\".format(train[:10]))\\n    print(\"test indices: {0}...\".format(test[:10]))\\n    \\n    ETC2 = RandomForestClassifier(n_estimators=50,criterion=\\'gini\\',max_depth=None,min_samples_split=2,\\n                                       min_samples_leaf=1,max_features=\\'auto\\',bootstrap=False,oob_score=False,\\n                                       n_jobs=-1,random_state=None,verbose=0).fit(X[train],y[train])\\n    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(ETC2.score(X[train], y[train]), \\n          ETC2.score(X[test], y[test])))\\n\\npredicted_values_ETC2 = cross_val_predict(ETC2, X, y, cv=10, n_jobs=-1)\\n'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for cv_index, (train, test) in enumerate(cv):\n",
    "    print(\"# Cross Validation Iteration #%d\" % cv_index)\n",
    "    print(\"train indices: {0}...\".format(train[:10]))\n",
    "    print(\"test indices: {0}...\".format(test[:10]))\n",
    "    \n",
    "    ETC2 = RandomForestClassifier(n_estimators=50,criterion='gini',max_depth=None,min_samples_split=2,\n",
    "                                       min_samples_leaf=1,max_features='auto',bootstrap=False,oob_score=False,\n",
    "                                       n_jobs=-1,random_state=None,verbose=0).fit(X[train],y[train])\n",
    "    print(\"train score: {0:.3f}, test score: {1:.3f}\\n\".format(ETC2.score(X[train], y[train]), \n",
    "          ETC2.score(X[test], y[test])))\n",
    "\n",
    "predicted_values_ETC2 = cross_val_predict(ETC2, X, y, cv=10, n_jobs=-1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicted_values_ETC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(predicted_values_ETC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF2_predict_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "lenval = len(svr_predicted_values) * -1\n",
    "y_actual = y[lenval:]\n",
    "results_df = pd.DataFrame(y_actual, index=y_actual.index)\n",
    "results_df['y_pred'] = svr_predicted_values\n",
    "\n",
    "\n",
    "def  prediction_labels(pred_data):\n",
    "    if pred_data > 0:\n",
    "        return 1\n",
    "    if pred_data < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "#results_df['y_pred_labels'] = list(map(prediction_labels,results_df['y_pred']))\n",
    "\n",
    "svc_predict_values = clf.predict(X_test)\n",
    "lenval_svc = len(svc_predict_values) * -1\n",
    "y_actual_svc = y[lenval_svc:]\n",
    "results_clf_df = pd.DataFrame(y_actual_svc,index=y_actual_svc.index)\n",
    "results_clf_df['y_pred_svc'] = svc_predict_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cm_r = confusion_matrix(results_df['labels'],results_df['y_pred_labels'])\n",
    "cm_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results_clf_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cm_svc = confusion_matrix(results_clf_df['labels'],results_clf_df['y_pred_svc'])\n",
    "cm_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results_df['y_pred'].apply(lambda x: np.exp(x))\n",
    "results_df['y_pred'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "svr_predicted_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RF2_Test_Shuffle_Confidence():\n",
    "    \n",
    "    st='^GSPC'\n",
    "    df1['y_future'] = df1[st].shift(-3)\n",
    "\n",
    "    df1['labels'] = list(map(dvar,df1[st],df1['y_future']))\n",
    "\n",
    "    X = pd.DataFrame(df1, index=df1.index)\n",
    "    y = pd.DataFrame(df1, index=df1.index)\n",
    "\n",
    "    X = X.drop(['y_future', 'labels'],axis=1)\n",
    "    y = df1['labels']\n",
    "    \n",
    "    for i in y:\n",
    "        np.random.shuffle(y)\n",
    "    \n",
    "    df1.dropna(inplace=True)\n",
    "\n",
    "    X = preprocessing.scale(X)\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(X,y, test_size=0.50)\n",
    "    \n",
    "    \n",
    "    RF2 = RandomForestClassifier(n_estimators=100,criterion='gini',max_depth=None,min_samples_split=2,\n",
    "                                       min_samples_leaf=1,max_features='auto',bootstrap=False,oob_score=False,\n",
    "                                       n_jobs=-1,random_state=None,verbose=0)\n",
    "    \n",
    "    RF2.fit(X_train, y_train)\n",
    "    \n",
    "    pred1 = RF2.predict(X_test)\n",
    "    confidence = RF2.score(X_test, y_test)\n",
    "    return pred1, confidence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    R2TS = RF2_Test_Shuffle_Confidence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
